{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gulfem93/ChatbotProject/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZGH6idfFybA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNDbN4hZh6LR",
        "outputId": "e673233e-5589-43b4-e759-9a7bee8f6770"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl_DCaN6HkXe",
        "outputId": "736afdf8-504e-48ef-e764-0d756fa7cde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wr4p37uGIrS",
        "outputId": "01c37035-2ea4-4f40-a829-2f0cafbee9d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "intents = json.loads(open('/content/drive/MyDrive/Machine Learning projects/Chatbot Project/intents.json').read())\n",
        "\n",
        "words = pickle.load(open(\"/content/drive/MyDrive/Machine Learning projects/Chatbot Project/words.pkl\", \"rb\"))\n",
        "classes = pickle.load(open(\"/content/drive/MyDrive/Machine Learning projects/Chatbot Project/classes.pkl\", \"rb\"))\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/Machine Learning projects/Chatbot Project/chatbot_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwG8LCWpPGqU"
      },
      "outputs": [],
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "\n",
        "  return sentence_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr5qIDtiPkN8"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(sentence):\n",
        "  sentence_words = clean_up_sentence(sentence)\n",
        "  bag = [0] * len(words)\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "\n",
        "  return np.array(bag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq22jcLUiVjq"
      },
      "outputs": [],
      "source": [
        "def get_response(intents_list, intents_json):\n",
        "  tag = intents_list[0]['intent']\n",
        "  list_of_intents = intents_json['intents']\n",
        "  for i in list_of_intents:\n",
        "    if i['tag'] == tag:\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2953BfJ6Q9Xk"
      },
      "outputs": [],
      "source": [
        "def predict_class(sentence):\n",
        "  bow = bag_of_words(sentence)\n",
        "  res = model.predict(np.array([bow]))[0]\n",
        "\n",
        "  ERROR_THRESH = 0.25\n",
        "  results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESH]\n",
        "\n",
        "  results.sort(key = lambda x: x[1], reverse = True)\n",
        "\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "\n",
        "  return return_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS3BNXW7W3Qu",
        "outputId": "e08c629b-0f3a-417c-b0b1-474bb32f508a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Good to see you again!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "I am your helper\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "I am not program for this, please ask appropriate query\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "You can call me Mind Reader.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Good to see you again!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Hi there, how can I help?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "College is open 8am-5pm Monday-Saturday!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  message = input(\"\")\n",
        "  ints = predict_class(message)\n",
        "  res = get_response(ints, intents)\n",
        "\n",
        "\n",
        "  print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USoRgo7Uhv6-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEwcrn9vO0eR6YavWsoJD2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}